---
name: Code Pruner
description: Intelligent code context pruning using SWE-Pruner to reduce token consumption while maintaining relevance
---

# Code Pruner Skill

## Overview

This skill provides intelligent code pruning capabilities to optimize context size for LLM interactions. It uses the locally-deployed **SWE-Pruner** model to analyze code and remove irrelevant portions based on a query, reducing token consumption by 23-54% while maintaining 95%+ accuracy.

### Based on SWE-Pruner

This Skill is built on top of [SWE-Pruner](https://github.com/Ayanami1314/swe-pruner), an intelligent code pruning tool designed specifically for software engineering scenarios.

**Upstream Project**:

- üì¶ GitHub: [Ayanami1314/swe-pruner](https://github.com/Ayanami1314/swe-pruner)
- ü§ó Model: [ayanami-kitasan/code-pruner](https://huggingface.co/ayanami-kitasan/code-pruner)

**Acknowledgments**: Thanks to the SWE-Pruner project for providing excellent code pruning capabilities.

## Prerequisites

- **SWE-Pruner Service**: Must be running on `http://localhost:8000`
- **WSL2**: Ubuntu 22.04 with mirrored networking
- **GPU**: NVIDIA GPU with CUDA support (recommended)
- **Disk Space**: ~5 GB on D drive

## Installation

### 1. Start SWE-Pruner Service

```powershell
cd C:\Users\bob_c\.gemini\antigravity\playground\code-pruner-skill\scripts
.\start-service.ps1
```

### 2. Verify Service

```powershell
.\check-service.ps1
```

Expected output:

```
‚úÖ SWE-Pruner ÊúçÂä°ËøêË°å‰∏≠
   ËøõÁ®ã ID: <PID>
   ÊúçÂä°Âú∞ÂùÄ: http://localhost:8000
```

## Usage

### When to Use This Skill

Use code pruning when:

- Viewing large files (> 500 lines)
- Analyzing specific functionality in a codebase
- Reducing context size before LLM analysis
- Focusing on relevant code sections

### Command: `prune_code`

Prune code to focus on specific functionality or query.

**Syntax:**

```python
prune_code(
    code: str,           # Source code to prune
    query: str,          # Focus query (e.g., "authentication logic")
    threshold: float = 0.7  # Relevance threshold (0.0-1.0)
) -> dict
```

**Returns:**

```python
{
    "score": 0.95,              # Relevance score (0.0-1.0)
    "pruned_code": "...",       # Pruned code
    "original_size": 1500,      # Original character count
    "pruned_size": 450,         # Pruned character count
    "reduction_rate": 70.0      # Percentage reduced
}
```

### Examples

#### Example 1: Focus on Authentication

```python
code = """
def authenticate_user(username, password):
    if verify_credentials(username, password):
        return create_session(username)
    return None

def create_session(username):
    session_id = generate_session_id()
    store_session(session_id, username)
    return session_id

def logout_user(session_id):
    delete_session(session_id)

def send_email(to, subject, body):
    # Email sending logic
    pass
"""

result = prune_code(code, "focus on authentication logic")
# Returns only authenticate_user and create_session functions
```

#### Example 2: Payment Processing

```python
code = open("payment_module.py").read()
result = prune_code(code, "payment validation and processing")

print(f"Reduced by {result['reduction_rate']:.1f}%")
print(f"Relevance: {result['score']:.1%}")
```

#### Example 3: Custom Threshold

```python
# More aggressive pruning
result = prune_code(code, "database queries", threshold=0.8)
```

## Service Lifecycle

### Automatic Management

The service is automatically managed by the Skill:

- **Startup**: Service starts automatically on first Skill invocation
- **Running**: Remains active during coding sessions
- **Shutdown**: Manually stop before gaming to release GPU

### Manual Control

```powershell
# Start service
.\scripts\start-service.ps1

# Stop service (before gaming)
.\scripts\stop-service.ps1

# Check status
.\scripts\check-service.ps1
```

### Using Service Manager

```python
from tools.service_manager import get_service_manager

# Get manager instance
manager = get_service_manager()

# Prune with automatic service management
result = manager.prune_with_lifecycle(
    code=code,
    query="focus on authentication"
)

# Check service status
status = manager.check_service()
print(f"Service running: {status['running']}")
print(f"Usage count: {status['usage_count']}")
```

## Best Practices

### 1. Query Formulation

**Good queries:**

- "authentication and session management"
- "database connection and queries"
- "error handling for API calls"

**Poor queries:**

- "code" (too vague)
- "everything" (defeats the purpose)
- "line 42" (too specific, use view_file instead)

### 2. Threshold Selection

| Threshold | Use Case | Reduction | Accuracy |
|-----------|----------|-----------|----------|
| 0.5-0.6 | Aggressive pruning | 50-70% | 85-90% |
| 0.7-0.8 | Balanced (default) | 30-50% | 95%+ |
| 0.9+ | Conservative | 10-30% | 99%+ |

### 3. Performance Considerations

- **First call**: ~2-3 seconds (model loading)
- **Subsequent calls**: < 1 second
- **GPU memory**: ~2 GB
- **Service startup**: ~30 seconds

### 4. When NOT to Use

- Small files (< 100 lines) - overhead not worth it
- Already focused code snippets
- When you need the complete file structure
- During service downtime

## Workflow Integration

### Recommended Pattern

```python
# 1. Check file size first
file_size = len(open("large_module.py").read())

if file_size > 2000:  # > 2000 characters
    # 2. Prune before analysis
    result = prune_code(code, "focus on error handling")
    code_to_analyze = result['pruned_code']
else:
    # 3. Use original for small files
    code_to_analyze = code

# 4. Proceed with analysis
analyze_code(code_to_analyze)
```

## Service Management

### Start Service

```powershell
.\scripts\start-service.ps1
```

### Stop Service (Before Gaming)

```powershell
.\scripts\stop-service.ps1
```

### Check Status

```powershell
.\scripts\check-service.ps1
```

### View Logs

```powershell
wsl -d Ubuntu-22.04 -- tail -f /tmp/swe-pruner.log
```

## Troubleshooting

### Service Not Responding

```powershell
# Check if service is running
.\scripts\check-service.ps1

# Restart service
.\scripts\stop-service.ps1
.\scripts\start-service.ps1
```

### Network Errors

Verify WSL2 network configuration:

```powershell
# Check .wslconfig
cat C:\Users\bob_c\.wslconfig

# Should contain:
# [wsl2]
# networkingMode=mirrored
```

### GPU Not Detected

```bash
# Check CUDA availability
wsl -d Ubuntu-22.04 -- nvidia-smi
```

## Performance Metrics

Based on deployment testing:

- **Average Reduction**: 40-50%
- **Average Relevance**: 95%+
- **Response Time**: < 1 second
- **Token Savings**: 1000-5000 tokens per request

## Implementation Details

### Tool Location

`tools/prune_code.py` - Python wrapper for API calls

### Scripts Location

- `scripts/start-service.ps1` - Start SWE-Pruner
- `scripts/stop-service.ps1` - Stop SWE-Pruner
- `scripts/check-service.ps1` - Check status

### Service Details

- **Endpoint**: `http://localhost:8000/prune`
- **Method**: POST
- **Model**: ayanami-kitasan/code-pruner (1.3 GB)
- **Backbone**: Qwen3-Reranker-0.6B

## References

- [SWE-Pruner Repository](https://github.com/ayanami-kitasan/code-pruner)
- [Deployment Guide](docs/deployment.md)
- [Configuration](docs/configuration.md)
